{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa343262-ae85-46d7-ad2a-0fe6698712d4",
   "metadata": {},
   "source": [
    "## Dealing with missing data and lift rate effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e771214b-af1f-4be5-9750-39aa23e4bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import pandas as pd\n",
    "import itertools as itt\n",
    "import arviz as az\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import importlib as imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90e319be-1733-4ff7-a4de-5702f4ae650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df = pd.read_csv(\"melted_data.csv\")\n",
    "df = pd.read_csv(\"data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f88fb59-4627-4ae1-98cb-6f6725fd47a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2 bends in 10 minutes', '2 bends in 5 minutes',\n",
       "       '3 bends in 8 minutes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_obs = df.copy()\n",
    "full_obs = full_obs.dropna()\n",
    "\n",
    "#lift rates\n",
    "int_lift_rates = full_obs['Intervention Average Lift Rate'].values.reshape(-1, 1)\n",
    "base_lift_rates = full_obs['Baseline Average Lift Rate'].values.reshape(-1, 1)\n",
    "\n",
    "#scores\n",
    "int_scores = full_obs['Intervention Average Safety Score'].values.reshape(-1, 1)\n",
    "base_scores = full_obs['Baseline Average Safety Score'].values.reshape(-1, 1)\n",
    "\n",
    "#treatments\n",
    "int_treatments = pd.get_dummies(full_obs['Haptic Group'])\n",
    "tr_names = int_treatments.columns\n",
    "treatments = int_treatments.values\n",
    "tr_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a494681-5192-49fa-a211-3d46a179585b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurimas/apps/anaconda3/envs/strongarm/lib/python3.10/site-packages/pymc/data.py:647: FutureWarning: The `mutable` kwarg was not specified. Currently it defaults to `pm.Data(mutable=True)`, which is equivalent to using `pm.MutableData()`. In v4.1.0 the default will change to `pm.Data(mutable=False)`, equivalent to `pm.ConstantData`. Set `pm.Data(..., mutable=False/True)`, or use `pm.ConstantData`/`pm.MutableData`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as m:\n",
    "    \n",
    "    #register the data\n",
    "    scores = pm.Data(\"scores\", np.concatenate([base_scores, int_scores]))    \n",
    "    \n",
    "    b_rates = pm.Data(\"baseline_rates\", base_lift_rates)\n",
    "    i_rates = pm.Data(\"intervention_rates\", int_lift_rates)\n",
    "    \n",
    "    treats = pm.Data(\"treatments\", treatments)\n",
    "    no_treats = pm.Data(\"baseline\", np.zeros(treatments.shape))\n",
    "    \n",
    "    #priors\n",
    "    α = pm.Normal(\"lift_alpha\", 0, sigma=10)\n",
    "    lift_treatment = pm.Normal(\"lift_treatment\", 0, sigma=10, shape=(treatments.shape[1], 1))\n",
    "    ind_effect_sigma = pm.HalfCauchy(\"lift_ind_error\", beta=5)\n",
    "    ind_effects = pm.Normal(\"lift_fixed\", 0, sigma=ind_effect_sigma, shape=(base_lift_rates.shape[0], 1))\n",
    "\n",
    "    #obtain impact of treatment to lift scores    \n",
    "    pred_lift_rates = α + b_rates + ind_effects + pm.math.dot(treats, lift_treatment)\n",
    "    \n",
    "    #estimate intervention lift rates\n",
    "    residual_var = pm.HalfCauchy(\"lift_error\", beta=5)\n",
    "    est_int_rates = pm.Normal('lift_int', mu=pred_lift_rates, sigma = residual_var, observed = i_rates)\n",
    "    \n",
    "    #stack the data together\n",
    "    lift_rates_stacked = pm.math.concatenate([b_rates, est_int_rates], axis=0)\n",
    "    treatments_stacked = pm.math.concatenate([no_treats, treats], axis=0)\n",
    "    \n",
    "    #priors\n",
    "    alpha = pm.Normal(\"score_alpha\", 0, sigma=50)\n",
    "    lift_beta = pm.Normal(\"score_lift\", 0, sigma=10)\n",
    "    treatment_betas = pm.Normal(\"score_treatment\", 0, sigma=10, shape=(treatments.shape[1], 1))\n",
    "    score_ind_effect_sigma = pm.HalfCauchy(\"score_ind_error\", beta=5)\n",
    "    fixed_effects = pm.Normal(\"score_fixed\", 0, sigma=score_ind_effect_sigma, shape=(base_lift_rates.shape[0], 1))\n",
    "    \n",
    "    #stack as needed    \n",
    "    fixed_effects_stacked = pm.math.concatenate([fixed_effects, fixed_effects], axis=0)\n",
    "    \n",
    "    #calculate score    \n",
    "    s = alpha + (lift_beta * lift_rates_stacked) + fixed_effects_stacked + pm.math.dot(treatments_stacked, treatment_betas)\n",
    "    \n",
    "    #likelihood\n",
    "    error_var = pm.HalfCauchy(\"score_error\", beta=5)\n",
    "    pm.Normal('likelihood', mu = s, sigma = error_var, observed = scores)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b92a7a42-882b-47e7-b7f0-228773245aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "/home/aurimas/apps/anaconda3/envs/strongarm/lib/python3.10/site-packages/pymc/aesaraf.py:1005: UserWarning: The parameter 'updates' of aesara.function() expects an OrderedDict, got <class 'dict'>. Using a standard dictionary here results in non-deterministic behavior. You should use an OrderedDict if you are using Python 2.7 (collections.OrderedDict for older python), or use a list of (shared, update) pairs. Do not just convert your dictionary to this type before the call as the conversion will still be non-deterministic.\n",
      "  aesara_function = aesara.function(\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [lift_alpha, lift_treatment, lift_ind_error, lift_fixed, lift_error, score_alpha, score_lift, score_treatment, score_ind_error, score_fixed, score_error]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 01:26<00:00 Sampling 4 chains, 544 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 87 seconds.\n",
      "There were 5 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.8887, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 14 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 525 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.5178, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    }
   ],
   "source": [
    "with m:\n",
    "    trace = pm.sample(return_inferencedata = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7d72c6-1ed9-420d-b0d0-5db2d7b28402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5%</th>\n",
       "      <th>hdi_95%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lift_alpha</th>\n",
       "      <td>-6.074</td>\n",
       "      <td>5.029</td>\n",
       "      <td>-15.026</td>\n",
       "      <td>1.269</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.384</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lift_treatment[0, 0]</th>\n",
       "      <td>-0.355</td>\n",
       "      <td>5.438</td>\n",
       "      <td>-8.044</td>\n",
       "      <td>8.868</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.666</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lift_treatment[1, 0]</th>\n",
       "      <td>-3.964</td>\n",
       "      <td>5.422</td>\n",
       "      <td>-11.768</td>\n",
       "      <td>5.599</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.400</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lift_treatment[2, 0]</th>\n",
       "      <td>-3.214</td>\n",
       "      <td>5.406</td>\n",
       "      <td>-11.360</td>\n",
       "      <td>6.143</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.274</td>\n",
       "      <td>228.0</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_alpha</th>\n",
       "      <td>78.855</td>\n",
       "      <td>1.085</td>\n",
       "      <td>76.837</td>\n",
       "      <td>80.300</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.210</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_lift</th>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>21.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_treatment[0, 0]</th>\n",
       "      <td>0.705</td>\n",
       "      <td>0.429</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>1.328</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.031</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_treatment[1, 0]</th>\n",
       "      <td>0.731</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.053</td>\n",
       "      <td>1.402</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.049</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_treatment[2, 0]</th>\n",
       "      <td>-0.341</td>\n",
       "      <td>0.418</td>\n",
       "      <td>-1.041</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.037</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2497.0</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lift_ind_error</th>\n",
       "      <td>9.998</td>\n",
       "      <td>7.903</td>\n",
       "      <td>0.285</td>\n",
       "      <td>20.633</td>\n",
       "      <td>3.463</td>\n",
       "      <td>2.631</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lift_error</th>\n",
       "      <td>15.279</td>\n",
       "      <td>6.652</td>\n",
       "      <td>3.449</td>\n",
       "      <td>21.784</td>\n",
       "      <td>3.033</td>\n",
       "      <td>2.290</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_ind_error</th>\n",
       "      <td>3.848</td>\n",
       "      <td>0.231</td>\n",
       "      <td>3.486</td>\n",
       "      <td>4.231</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.008</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2688.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_error</th>\n",
       "      <td>2.622</td>\n",
       "      <td>0.123</td>\n",
       "      <td>2.412</td>\n",
       "      <td>2.808</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>2255.0</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean     sd  hdi_5%  hdi_95%  mcse_mean  mcse_sd  \\\n",
       "lift_alpha             -6.074  5.029 -15.026    1.269      0.435    0.384   \n",
       "lift_treatment[0, 0]   -0.355  5.438  -8.044    8.868      0.933    0.666   \n",
       "lift_treatment[1, 0]   -3.964  5.422 -11.768    5.599      0.564    0.400   \n",
       "lift_treatment[2, 0]   -3.214  5.406 -11.360    6.143      0.387    0.274   \n",
       "score_alpha            78.855  1.085  76.837   80.300      0.291    0.210   \n",
       "score_lift             -0.114  0.009  -0.130   -0.099      0.002    0.002   \n",
       "score_treatment[0, 0]   0.705  0.429  -0.046    1.328      0.044    0.031   \n",
       "score_treatment[1, 0]   0.731  0.427   0.053    1.402      0.069    0.049   \n",
       "score_treatment[2, 0]  -0.341  0.418  -1.041    0.305      0.052    0.037   \n",
       "lift_ind_error          9.998  7.903   0.285   20.633      3.463    2.631   \n",
       "lift_error             15.279  6.652   3.449   21.784      3.033    2.290   \n",
       "score_ind_error         3.848  0.231   3.486    4.231      0.012    0.008   \n",
       "score_error             2.622  0.123   2.412    2.808      0.004    0.003   \n",
       "\n",
       "                       ess_bulk  ess_tail  r_hat  \n",
       "lift_alpha                132.0    2206.0   1.03  \n",
       "lift_treatment[0, 0]       35.0    1938.0   1.08  \n",
       "lift_treatment[1, 0]      105.0    1989.0   1.03  \n",
       "lift_treatment[2, 0]      228.0    2027.0   1.02  \n",
       "score_alpha                15.0      37.0   1.19  \n",
       "score_lift                 21.0     144.0   1.13  \n",
       "score_treatment[0, 0]     105.0    2306.0   1.03  \n",
       "score_treatment[1, 0]      41.0    1518.0   1.07  \n",
       "score_treatment[2, 0]      64.0    2497.0   1.04  \n",
       "lift_ind_error              6.0      25.0   1.94  \n",
       "lift_error                  6.0      12.0   1.85  \n",
       "score_ind_error           400.0    2688.0   1.00  \n",
       "score_error              1045.0    2255.0   1.05  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = az.summary(trace, hdi_prob=0.9)\n",
    "rel_idx = [i for i in results.index if 'fixed' not in i]\n",
    "results.loc[rel_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e057d300-95d2-437b-958a-95f7d32ed099",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace, figsize=(30,30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strongarm",
   "language": "python",
   "name": "strongarm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
